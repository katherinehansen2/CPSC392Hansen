{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qPr4nRs8nqet"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from plotnine import *\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler, LabelBinarizer #Z-score variables\n",
        "\n",
        "from sklearn.model_selection import train_test_split # simple TT split cv\n",
        "from sklearn.model_selection import KFold # k-fold cv\n",
        "from sklearn.model_selection import LeaveOneOut #LOO cv\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix,\\\n",
        " f1_score, recall_score, precision_score, roc_auc_score\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay\n",
        "\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Together"
      ],
      "metadata": {
        "id": "zMtBu6c1nv66"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes\n",
        "\n",
        "Let's use the Naive Bayes algorithm to predict the mode of Beyonce songs, using the predictors energy, danceability, and valence.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PGQvvo5hrVPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "beyonce = pd.read_csv(\"https://raw.githubusercontent.com/katherinehansen2/CPSC392Hansen/refs/heads/main/data/Beyonce_data.csv\")\n",
        "beyonce.head()"
      ],
      "metadata": {
        "id": "aj8MJzUYnxHH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: What are the data types of the predictors? What kind of NB should we use?"
      ],
      "metadata": {
        "id": "lyfj7fsoro7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictors = [\"energy\", \"danceability\", \"valence\"]\n",
        "\n",
        "X = beyonce[predictors]\n",
        "y = beyonce[\"mode\"]\n",
        "\n",
        "# TTS\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2)\n",
        "\n",
        "# Z-score\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# create model\n",
        "nb = # TODO\n",
        "\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "y_pred_train = nb.predict(X_train)\n",
        "y_pred_test = nb.predict(X_test)\n",
        "\n",
        "y_pred_train_prob = nb.predict_proba(X_train)[:,1]\n",
        "y_pred_test_prob = nb.predict_proba(X_test)[:,1]"
      ],
      "metadata": {
        "id": "f021Jq8Ury7h"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assess\n",
        "print(\"Train Acc       : \", accuracy_score(y_train, y_pred_train))\n",
        "print(\"Train Prescision: \", precision_score(y_train, y_pred_train))\n",
        "print(\"Train Recall    : \", recall_score(y_train, y_pred_train))\n",
        "print(\"Train F1        : \", f1_score(y_train, y_pred_train))\n",
        "print(\"Train ROC AUC   : \", roc_auc_score(y_train, y_pred_train_prob))\n",
        "print()\n",
        "print(\"Test Acc        : \", accuracy_score(y_test, y_pred_test))\n",
        "print(\"Test Prescision : \", precision_score(y_test, y_pred_test))\n",
        "print(\"Test Recall     : \", recall_score(y_test, y_pred_test))\n",
        "print(\"Test F1         : \", f1_score(y_test, y_pred_test))\n",
        "print(\"Test ROC AUC    : \", roc_auc_score(y_test, y_pred_test_prob))"
      ],
      "metadata": {
        "id": "nPjDzsyjsson"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN"
      ],
      "metadata": {
        "id": "BbnO5TuXs11x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's do the same prediction, excpet using a KNN algorithm.\n",
        "\n",
        "Remember, we'll need to select the hyperparameter n_neighbors, and we'll do this using a Grid Search.\n",
        "\n",
        "TODO: Discussion - why do we need to use a validation set?"
      ],
      "metadata": {
        "id": "8GZQv_lQs2qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load in + prepare data\n",
        "beyonce = pd.read_csv(\"https://raw.githubusercontent.com/katherinehansen2/CPSC392Hansen/refs/heads/main/data/Beyonce_data.csv\")\n",
        "\n",
        "predictors = [\"energy\", \"danceability\", \"valence\"]\n",
        "X = beyonce[predictors]\n",
        "y = beyonce[\"mode\"]\n",
        "\n",
        "# TTS\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2)\n",
        "\n",
        "# Z-score\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# define KNN Model\n",
        "\n",
        "knn = # TODO\n",
        "\n",
        "# Select values you want to search over\n",
        "hparams = # TODO\n",
        "\n",
        "# define your GridSearchCV()\n",
        "grid = GridSearchCV(#, #, scoring = \"precision\", cv = 5, refit = True)\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"GridSearchCV chose: \", grid.best_estimator_.get_params()[\"n_neighbors\"])\n"
      ],
      "metadata": {
        "id": "BhG35h71uOCT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict\n",
        "y_pred_train = grid.predict(X_train)\n",
        "y_pred_test = grid.predict(X_test)\n",
        "\n",
        "y_pred_train_prob = grid.predict_proba(X_train)[:,1]\n",
        "y_pred_test_prob = grid.predict_proba(X_test)[:,1]"
      ],
      "metadata": {
        "id": "f0gNUQwSu9po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assess\n",
        "print(\"Train Acc       : \", accuracy_score(y_train, y_pred_train))\n",
        "print(\"Train Prescision: \", precision_score(y_train, y_pred_train))\n",
        "print(\"Train Recall    : \", recall_score(y_train, y_pred_train))\n",
        "print(\"Train F1        : \", f1_score(y_train, y_pred_train))\n",
        "print(\"Train ROC AUC   : \", roc_auc_score(y_train, y_pred_train_prob))\n",
        "print()\n",
        "print(\"Test Acc        : \", accuracy_score(y_test, y_pred_test))\n",
        "print(\"Test Prescision : \", precision_score(y_test, y_pred_test))\n",
        "print(\"Test Recall     : \", recall_score(y_test, y_pred_test))\n",
        "print(\"Test F1         : \", f1_score(y_test, y_pred_test))\n",
        "print(\"Test ROC AUC    : \", roc_auc_score(y_test, y_pred_test_prob))"
      ],
      "metadata": {
        "id": "j5pyVE7lu_Qs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Discussion - which model (KNN or NB) performed better for this dataset? How did you make that decision?"
      ],
      "metadata": {
        "id": "Aljs2VCuvBL8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Boundaries Plots\n",
        "\n",
        "\n",
        "We can use sklearn's built in DecisionBoundaryDisplay() to view the boundaries we've made. Note: We can only do this in 2D, so we'll select two of our predictors to look at"
      ],
      "metadata": {
        "id": "e6Fe6zeGviqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X[['energy', 'danceability']]\n",
        "\n",
        "# note - the amount you add/subtract (0.05) should be dependent on the scale of your column\n",
        "# our columns have very small numbers, so I set it to be very small\n",
        "feature_1, feature_2 = np.meshgrid(\n",
        "    np.linspace(X['energy'].min() - 0.05, X['energy'].max() + 0.05),\n",
        "    np.linspace(X['danceability'].min() - 0.05, X['danceability'].max() + 0.05)\n",
        ")\n",
        "\n",
        "grid = np.vstack([feature_1.ravel(), feature_2.ravel()]).T\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors = 3).fit(X, y)\n",
        "\n",
        "y_pred = np.reshape(knn.predict(grid), feature_1.shape)\n",
        "display = DecisionBoundaryDisplay(\n",
        "    xx0=feature_1, xx1=feature_2, response=y_pred\n",
        ")\n",
        "display.plot()\n",
        "\n",
        "display.ax_.scatter(\n",
        "    X['energy'], X['danceability'], c=y, edgecolor=\"black\"\n",
        ")\n",
        "\n",
        "display.ax_.set_title(\"KNN Decision Boundary (k = 3)\")\n",
        "display.ax_.set_xlabel('Energy')\n",
        "display.ax_.set_ylabel('danceability')\n",
        "display.ax_.legend()"
      ],
      "metadata": {
        "id": "5lUFB-oZvh7R"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ICA"
      ],
      "metadata": {
        "id": "AnGiB44onxNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wine Data"
      ],
      "metadata": {
        "id": "kZdRhdTzydm9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the [wine quality dataset](https://www.kaggle.com/datasets/ruthgn/wine-quality-data-set-red-white-wine). The code below creates a new column, is_white, which has a 1 where a wine is white and a 0 otherwise. Build both a KNN and a NB model to predict the is_white column.\n",
        "\n"
      ],
      "metadata": {
        "id": "s3TtENUdw-Bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(# TODO - link)\n",
        "\n",
        "data['is_white'] = (data['type'] == 'white').astype(int)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "CEjL6XK6xqHM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Which kind of NB will you use here? Why?"
      ],
      "metadata": {
        "id": "jDpgx6jdxm1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NB\n",
        "\n"
      ],
      "metadata": {
        "id": "t-JiZZWlxlzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Discuss the performance of your NB Model"
      ],
      "metadata": {
        "id": "410-Iux3yHhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN\n",
        "\n"
      ],
      "metadata": {
        "id": "SDJ8fnBhyKKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Which n_neighbors was best? Discuss the performance of your KNN model. Which performed better, KNN or NB?"
      ],
      "metadata": {
        "id": "FE6OJ5AIyLNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Witch Data"
      ],
      "metadata": {
        "id": "7Svfjn_3yavP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to use some data about alleged witches to predict whether someone is a witch. Load in the salem.csv file from GitHub. The dataset contains the following variables:\n",
        "* age\n",
        "* marital_status: Single, Widowed, Married, Divorced\n",
        "* occupation: Farmer, Midwife, Homemaker, Merchant\n",
        "* pet_ownership: binary indicator of if person owns pet\n",
        "* unusual_knowledge: binary indicator of if person has unusual knowlege\n",
        "* num_children\n",
        "* acres_owned: # of acres owned by person\n",
        "* income: income in dollars\n",
        "* years_of_education\n",
        "* is_witch: binary variable indicating if subject is a witch"
      ],
      "metadata": {
        "id": "Pkzw4REgyfNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "witches = pd.read_csv(\"https://raw.githubusercontent.com/katherinehansen2/CPSC392Hansen/refs/heads/main/data/salem.csv\")\n",
        "witches.head()"
      ],
      "metadata": {
        "id": "ii2fbBno2P8U"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NB\n",
        "\n",
        "TODO: Use GaussianNB to predict the is_witch column using all of the continuous predictors"
      ],
      "metadata": {
        "id": "Ql8sqThp2YgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GaussianNB\n"
      ],
      "metadata": {
        "id": "80J4S0DC2d2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Use CategoricalNB to predict the is_witch column using marital_status and occupation. Hint: You'll need to use dummy variables/one hot encoding."
      ],
      "metadata": {
        "id": "15dp-0O72e6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CategoricalNB\n"
      ],
      "metadata": {
        "id": "mCP-zXos2qMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN\n",
        "TODO: Build a KNN model to predict is_witch using all predictors. What was the K chosen by grid search?"
      ],
      "metadata": {
        "id": "_Dsag8f82sJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN"
      ],
      "metadata": {
        "id": "Vl0pKiYC27-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Which of those 3 models performed the best? Why?"
      ],
      "metadata": {
        "id": "AAq55sNW203I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trees\n",
        "\n",
        "We discussed how decision trees have more than one hyperparameter to check (min_samples_leaf and max_depth). Let's get practice using GridSearchCV for more than one hyperparameter.\n",
        "\n",
        "\n",
        "Use all of the predictors to build a DecisionTree.\n",
        "\n",
        "Try the hyperparameter options of:\n",
        "max_depth : [2, 3, 4, 5]\n",
        "min_samples_leaf: [2, 3, 4]"
      ],
      "metadata": {
        "id": "fKsp4idC297t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictors = [\"age\", \"marital_status\", \"occupation\", \"pet_ownership\",\t\"unusual_knowledge\", \"num_children\", \"acres_owned\",\t\"income\",\t\"years_of_education\"]\n",
        "contin = [\"age\", \"num_children\", \"acres_owned\", \"income\", \"years_of_education\"]\n",
        "categ = [\"marital_status\", \"occupation\"]\n",
        "\n",
        "X = witches[predictors]\n",
        "y = witches[\"is_witch\"]\n",
        "\n",
        "# dummy categorical predictors\n",
        "X = pd.get_dummies(X, columns=categ)\n",
        "\n",
        "# TTS\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2)\n",
        "\n",
        "# Z-score continuous\n",
        "# Z-score\n",
        "scaler = StandardScaler()\n",
        "X_train[contin] = scaler.fit_transform(X_train[contin])\n",
        "X_test[contin] = scaler.transform(X_test[contin])\n",
        "\n",
        "\n",
        "# Define Decision Tree\n",
        "\n",
        "tree = DecisionTreeClassifier()\n",
        "\n",
        "# Select values you want to search over\n",
        "hparams = {\"max_depth\": # TODO: fill in desired values,\n",
        "           \"min_samples_leaf\": # TODO: fill in desired values}\n",
        "\n",
        "# define your GridSearchCV()\n",
        "grid = GridSearchCV(tree, hparams, scoring = \"precision\", cv = 5, refit = True)\n",
        "\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"GridSearchCV chose:\", grid.best_estimator_.get_params()[\"max_depth\"], \"max depth\")\n",
        "print(\"GridSearchCV chose:\", grid.best_estimator_.get_params()[\"min_samples_leaf\"], \"min samples leaf\")"
      ],
      "metadata": {
        "id": "zR0Tsr1L3QQP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Which hyperparameters were chosen?"
      ],
      "metadata": {
        "id": "9oRwqS_85aey"
      }
    }
  ]
}