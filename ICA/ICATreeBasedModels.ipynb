{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eExmK9XHCGiG"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from plotnine import *\n",
        "\n",
        "# models\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor # Decision Tree\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor # random forest\n",
        "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor # gradient boosting\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# preprocessing\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelBinarizer\n",
        "\n",
        "# model validation\n",
        "from sklearn.model_selection import train_test_split # simple TT split cv\n",
        "from sklearn.model_selection import KFold # k-fold cv\n",
        "from sklearn.model_selection import LeaveOneOut #LOO cv\n",
        "\n",
        "# performance\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix,\\\n",
        " f1_score, recall_score, precision_score, roc_auc_score\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tree-based models\n",
        "\n",
        "## Some Review\n",
        "|                     | **Decision Tree**         | **Random Forest**                  | **Gradient Boosting Tree** |\n",
        "|---------------------|---------------------------|------------------------------------|----------------------------|\n",
        "| _num trees_         | one                       | many                               | many                       |\n",
        "| _make predictions_  | mode or mean of leaf node | each tree votes                    | sum of tree outputs        |\n",
        "| _tree independence_ | NOT applicable            | independent                        | dependent                  |\n",
        "| _Data Used_         | all                       | bagging + random feature selection | all                        |\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1PgupmQER9-enXETnyxbLTihgub5B5_Bm\" alt=\"Q\" width = \"200\"/>\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1G0iSNeEwvhiTiMwW2jS1HPjo_2Wt_OOn\" alt=\"Q\" width = \"600\"/>\n",
        "</p>\n",
        "\n",
        "TODO: thinking ðŸŒ²\n",
        "\n",
        "Either discuss 1-2 these with your table, or write a short response to 1-2.\n",
        "- Think about how a prediction is made in a Decision (or Regression) Tree. Does the **depth** of the tree affect how *long* it takes to make a prediction? Is the prediction slower, faster, or the same with more depth?\n",
        "- How does the number of **nodes** in a tree affect the amount of values we need to *store* to make a prediction using a trained Decision Tree? Does a tree with more nodes take more memory to store, less memory, or the same?\n",
        "- When we build a Random Forest, will making predictions be slower, faster, or the same speed? Will it take more, the same, or less memory than storing a Decision Tree?\n",
        "- When we build a Gradient Boosting Tree, will making predictions be slower, faster, or the same speed? Will it take more, the same, or less memory than storing a Decision Tree?\n",
        "- (Bonus: We've been talking about time and space complexity when making a *prediction*, but at training time, which could be faster: Random Forests or Gradient Boosting Trees?)\n",
        "\n"
      ],
      "metadata": {
        "id": "xY4cbgSoDaJk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Trees, Graphically\n",
        "\n",
        "Let's load in our penguin data set, and plot the bill length and bill depth for our three species"
      ],
      "metadata": {
        "id": "DWfj8bjuGUdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "penguin = pd.read_csv(\"https://raw.githubusercontent.com/katherinehansen2/CPSC392Hansen/refs/heads/main/data/penguins.csv\")\n",
        "penguin.head()"
      ],
      "metadata": {
        "id": "cfyX8xO_F2MU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(ggplot(penguin, aes(x = \"bill_length_mm\", y = \"bill_depth_mm\", color = \"species\")) + geom_point()\n",
        " + theme_minimal()\n",
        " + labs(x = \"Bill Length (in mm)\", y = \"Bill Depth (in mm)\", title = \"Bill Length vs. Bill Depth by Species\"))"
      ],
      "metadata": {
        "id": "DgdJFCuUGaXL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could use a decision tree based on bill length and bill depth to classify penguins as different species. First, we could split on Bill Depth and decide that any penguin with a depth less than 16.5 mm, should be classified as a Gentoo penguin."
      ],
      "metadata": {
        "id": "2twlHEcgGkAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split1 = # TODO\n",
        "\n",
        "(ggplot(penguin, aes(x = \"bill_length_mm\", y = \"bill_depth_mm\", color = \"species\")) + geom_point()\n",
        " + theme_minimal()\n",
        " + labs(x = \"Bill Length (in mm)\", y = \"Bill Depth (in mm)\", title = \"Bill Length vs. Bill Depth by Species\")\n",
        " + geom_hline(yintercept = split1, size = 1, linetype = \"dashed\"))"
      ],
      "metadata": {
        "id": "GMmR4YpkGjTy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That bottom group looks GREAT. Now let's look at the top group. Most of the Chinstrap penguins have longer bill lengths. Let's say that if a penguin has a bill depth > 16.5mm, then we will split on bill length at 41.5 to separate the Adelie and Chinstrap penguins."
      ],
      "metadata": {
        "id": "LCJSfNk4G2tH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split2 = # TODO\n",
        "\n",
        "(ggplot(penguin, aes(x = \"bill_length_mm\", y = \"bill_depth_mm\", color = \"species\")) + geom_point()\n",
        " + theme_minimal()\n",
        " + labs(x = \"Bill Length (in mm)\", y = \"Bill Depth (in mm)\", title = \"Bill Length vs. Bill Depth by Species\")\n",
        " + geom_hline(yintercept = split1, size = 1, linetype = \"dashed\")\n",
        " + geom_segment(x = split2, xend = split2, y = split1, yend = 22, size = 0.6, linetype = \"dashed\", color = \"black\"))"
      ],
      "metadata": {
        "id": "kgyC7YG0G3Us"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've built a (very short) decision tree! It would look like this.\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1wMi2k4RI9RuYq-NcHRVm7b62p4UwUXSh\" width = \"400\"/>\n",
        "</p>"
      ],
      "metadata": {
        "id": "0vgP5hH3G9my"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gini Impurity & Entropy - Reading\n",
        "\n",
        "You can make split decisions based either on gini impurity or entropy.\n",
        "\n",
        "Entropy is a measure of disorder/chaos. We want ordered and organized data in the leaf nodes of our decision trees. So we want LOW entropy. **Entropy** is defined as:\n",
        "\n",
        "$$ E = -\\sum_1^N p_i* log_2(p_i) $$\n",
        "\n",
        "Where $N$ is the number of categories or labels in our outcome variable.\n",
        "\n",
        "This is compared to **gini impurity** which is:\n",
        "\n",
        "$$GI = 1 - \\sum_1^N p_i^2$$\n",
        "\n",
        "Gini impurity is probability of misclassifying a random data point from that node.\n",
        "\n",
        "## Measures of Chaos for a Split\n",
        "\n",
        "When you split a node, we now have two new nodes. In order to calculate the chaos (entropy or gini impurity) of the split, we have to calculate the chaos (entropy or gini impurity) for EACH of the new nodes and then calculate the weighted average chaos (entropy or gini impurity).  \n",
        "\n",
        "The reason we weight each node differently in this calculation, is because if a node has more data in it, than it has more impact, and therefore its measure of chaos (entropy or gini impurity) should count more.\n",
        "\n",
        "In general, once you've calculated the chaos (entropy or gini impurity) for each of the new nodes, you'll use this formula to calculate the weighted average:\n",
        "\n",
        "\n",
        "$$ WC = (\\frac{N_L}{Total}* C_L) + (\\frac{N_R}{Total}* C_R)$$\n",
        "\n",
        "Where $N_L$ is the number of data points in the Left Node, $N_R$ is the number of data points in the Right Node, and $Total$ is the total number of data points in that split. $C_R$ and $C_L$ are the chaos measure (entropy of gini impurity) for the right and left nodes, respectively.\n",
        "\n",
        "\n",
        "\n",
        "(For more info on decision trees, check out this paper [Theoretical comparison between the Gini Index and\n",
        "Information Gain criteria](https://www.unine.ch/files/live/sites/imi/files/shared/documents/papers/Gini_index_fulltext.pdf))"
      ],
      "metadata": {
        "id": "DmDuKfouHkDI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Trees in sklearn\n",
        "\n",
        "Let's first build a Decision Tree to **classify** patients as diabetic or not diabetic."
      ],
      "metadata": {
        "id": "xruxdT54IdpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = pd.read_csv(\"https://raw.githubusercontent.com/katherinehansen2/CPSC392Hansen/refs/heads/main/data/diabetes2.csv\")\n",
        "d.head()"
      ],
      "metadata": {
        "id": "CJQ50PQeIg0A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictors = [\"Pregnancies\",\"Glucose\",\"BloodPressure\",\"SkinThickness\",\n",
        "              \"Insulin\",\"BMI\",\"DiabetesPedigreeFunction\",\"Age\"]\n",
        "X = d[predictors]\n",
        "y = d[\"Outcome\"]\n",
        "\n",
        "# z scoring not important, because none of the variables are influencing/compared to each other directly\n",
        "# scale doesn't matter here. But z scoring wont hurt.\n",
        "\n",
        "\n",
        "# TTS\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 1)\n",
        "\n",
        "\n",
        "tree = DecisionTreeClassifier(random_state = 1)\n",
        "\n",
        "\n",
        "# Fit\n",
        "tree.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Cxm3LiWyI4hT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ConfusionMatrixDisplay.from_predictions(y_train, tree.predict(X_train)))\n",
        "print(ConfusionMatrixDisplay.from_predictions(y_test, tree.predict(X_test)))"
      ],
      "metadata": {
        "id": "AloykWF_JPOU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Discuss the results of the confusion matrix above\n",
        "\n",
        "\n",
        "Below is code to see how \"deep\" your tree is"
      ],
      "metadata": {
        "id": "_3lA1SMlJSob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree.get_depth()"
      ],
      "metadata": {
        "id": "4Iz4GcuqJXYl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO:\n",
        "\n",
        "Create another decision tree to answer the same question as before,  but this time try limiting the max_depth and/or the min_samples_leaf"
      ],
      "metadata": {
        "id": "oh7B0dlbNOiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: See above"
      ],
      "metadata": {
        "id": "KBbMz0vJNXyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Discuss\n",
        "\n",
        "How did limiting your max_depth/min_samples_leaf impact your model's performace? What are some reasons we may want to implement these limitations?"
      ],
      "metadata": {
        "id": "SHbCZWjNNfeH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forests and Gradient Boosting Trees\n",
        "\n",
        "Now let's copy and paste the code from above and build a **Random Forest** to predict diabetes instead of a single tree, and then using a **Gradient Boosting Tree**."
      ],
      "metadata": {
        "id": "4Vxh4LK0Jknx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictors = [\"Pregnancies\",\"Glucose\",\"BloodPressure\",\"SkinThickness\",\n",
        "              \"Insulin\",\"BMI\",\"DiabetesPedigreeFunction\",\"Age\"]\n",
        "X = d[predictors]\n",
        "y = d[\"Outcome\"]\n",
        "\n",
        "# z scoring not important, because none of the variables are influencing/compared to each other directly\n",
        "# scale doesn't matter here. But z scoring wont hurt.\n",
        "\n",
        "\n",
        "# TTS\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 1234)\n",
        "\n",
        "\n",
        "rf = #\n",
        "\n",
        "\n",
        "# fit\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# predict/assess\n",
        "print(ConfusionMatrixDisplay.from_predictions(y_train, rf.predict(X_train)))\n",
        "print(ConfusionMatrixDisplay.from_predictions(y_test, rf.predict(X_test)))"
      ],
      "metadata": {
        "id": "HJuCJiFOJa-L"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictors = [\"Pregnancies\",\"Glucose\",\"BloodPressure\",\"SkinThickness\",\n",
        "              \"Insulin\",\"BMI\",\"DiabetesPedigreeFunction\",\"Age\"]\n",
        "X = d[predictors]\n",
        "y = d[\"Outcome\"]\n",
        "\n",
        "# z scoring not important, because none of the variables are influencing/compared to each other directly\n",
        "# scale doesn't matter here. But z scoring wont hurt.\n",
        "\n",
        "\n",
        "# TTS\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 1234)\n",
        "\n",
        "\n",
        "gb = #\n",
        "\n",
        "\n",
        "# fit\n",
        "gb.fit(X_train, y_train)\n",
        "\n",
        "# predict/assess\n",
        "print(ConfusionMatrixDisplay.from_predictions(y_train, gb.predict(X_train)))\n",
        "print(ConfusionMatrixDisplay.from_predictions(y_test, gb.predict(X_test)))"
      ],
      "metadata": {
        "id": "ys8ftxGVKP0u"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO:\n",
        "\n",
        "Discuss the performance compared to just a singular decision tree. Do you think this model is overfit, underfit, or neither?"
      ],
      "metadata": {
        "id": "Fkc5Uk_UJ6gd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trees, regression addition\n",
        "\n",
        "Let's use our penguin data to predict the bill_length_mm column."
      ],
      "metadata": {
        "id": "AlIM_ReCKyOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "penguins = pd.read_csv(\"https://raw.githubusercontent.com/katherinehansen2/CPSC392Hansen/refs/heads/main/data/penguins.csv\")\n",
        "penguins.head()"
      ],
      "metadata": {
        "id": "k9Jn0IJhLDEa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "penguins.dropna(inplace = True)\n",
        "\n",
        "predictors = [\"species\", \"island\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\", \"sex\"]\n",
        "categorical_predictors = [\"species\", \"island\", \"sex\"]\n",
        "\n",
        "\n",
        "\n",
        "# split into X/y\n",
        "X = penguins[predictors]\n",
        "X = pd.get_dummies(X, columns = categorical_predictors, drop_first=True)\n",
        "y = penguins[\"bill_length_mm\"]\n",
        "\n",
        "# TTS\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 1234)\n",
        "\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "jwOeWWpBLE8x"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict/assess\n",
        "print(mean_squared_error(y_train, rf.predict(X_train)))\n",
        "print(mean_squared_error(y_test, rf.predict(X_test)))"
      ],
      "metadata": {
        "id": "qTLD5YMCMh1F"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO:\n",
        "\n",
        "Repeat the process above, but with a GradientBoostingRegressor()"
      ],
      "metadata": {
        "id": "YeOEICp9M5Yf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: see above"
      ],
      "metadata": {
        "id": "eRiziLheM90D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra: Creating a small decision tree\n",
        "\n",
        "Bonus TODO:\n",
        "\n",
        "Time for more hands-on practice to help you understand what's going on behind the scenes. You are going to write gini impurity/entropy functions from scratch, and then use those to decide where to make a split.\n",
        "\n",
        "\n",
        "### Gini Impurity\n",
        "\n",
        "Use python and numpy to write two functions, as described in the comments below.\n",
        "\n",
        "- LNP: Left Node Positive (cases)\n",
        "- LNN: Left Node Negative (cases)\n",
        "- RNP: Right Node Positive (cases)\n",
        "- RNN: Right Node Negative (cases)\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src = \"https://drive.google.com/uc?id=1MQEeJDxxcV8zmhzBgaDZ2QY0Ng8z8hz8\" width = 300px/>\n",
        "</p>\n",
        "\n",
        "<hr>\n",
        "\n",
        "### Formulas\n",
        "\n",
        "$$GI = 1 - \\sum_1^N p_i^2$$\n",
        "\n",
        "Where $N$ is the number of categories or labels in our outcome variable.\n",
        "\n",
        "$$ WC = (\\frac{N_L}{Total}* C_L) + (\\frac{N_R}{Total}* C_R)$$\n",
        "\n",
        "Where $N_L$ is the number of data points in the Left Node, $N_R$ is the number of data points in the Right Node, and $Total$ is the total number of data points in that split. $C_R$ and $C_L$ are the chaos measure (entropy of gini impurity) for the right and left nodes, respectively.\n"
      ],
      "metadata": {
        "id": "A7aM656lN0kE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE ############\n",
        "\n",
        "\n",
        "def gini():\n",
        "    # this function calculates the gini impurity for ONE node (left, right, or root!)\n",
        "    # this function should take in the POSITIVE cases and NEGATIVE cases as arguments\n",
        "    # and calculate the gini impurity for that node based on the formula above\n",
        "    # return the impurity for the node.\n",
        "\n",
        "    # TODO\n",
        "\n",
        "    pass\n",
        "\n",
        "def gini_split():\n",
        "\n",
        "    # this function takes FOUR arguments: LNP, LNN, RNP, and RNN and calculates\n",
        "    # the gini impurity for each node (by calling gini()) and then calculates\n",
        "    # the WEIGHTED average of the impurity in each node.\n",
        "    # return the impurity for the split.\n",
        "\n",
        "    # TODO\n",
        "\n",
        "    pass\n",
        "\n",
        "### YOUR CODE HERE ###############"
      ],
      "metadata": {
        "id": "AJmJHfPbOVne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use this to test your code, if it prints True, you got the right answer\n",
        "\n",
        "abs(gini_split(10,5,2,12) - 0.3481116584564861) <= 0.0001"
      ],
      "metadata": {
        "id": "z9jhyNubOXRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entropy\n",
        "\n",
        "Use python and numpy to write two functions, as described by the comments below. If you want to read more about entropy, see this [article](https://bricaud.github.io/personal-blog/entropy-in-decision-trees/).\n",
        "\n",
        "hint: `np.log2()`\n",
        "\n",
        "<hr>\n",
        "\n",
        "### Formulas\n",
        "\n",
        "$$ E = -\\sum_1^N p_i* log_2(p_i) $$\n",
        "\n",
        "Where $N$ is the number of categories or labels in our outcome variable.\n",
        "\n",
        "$$ WC = (\\frac{N_L}{Total}* C_L) + (\\frac{N_R}{Total}* C_R)$$\n",
        "\n",
        "Where $N_L$ is the number of data points in the Left Node, $N_R$ is the number of data points in the Right Node, and $Total$ is the total number of data points in that split. $C_R$ and $C_L$ are the chaos measure (entropy of gini impurity) for the right and left nodes, respectively."
      ],
      "metadata": {
        "id": "AxvgPInKOefl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE ###############\n",
        "\n",
        "def entropy():\n",
        "    # this function calculates the entropy for ONE node (left, right, or root!)\n",
        "    # this function should take in the POSITIVE cases and NEGATIVE cases counts as arguments\n",
        "    # and calculate the entropy for that node based on the formula above\n",
        "\n",
        "    # TODO\n",
        "\n",
        "    pass\n",
        "\n",
        "def entropy_split():\n",
        "    # this function takes FOUR arguments: LNP, LNN, RNP, and RNN and calculates\n",
        "    # the entropy for each node (by calling entropy()) and then calculates\n",
        "    # the WEIGHTED average of the entropy in each node.\n",
        "    # return the entropy for the split.\n",
        "\n",
        "    # TODO\n",
        "\n",
        "    pass\n",
        "\n",
        "### YOUR CODE HERE ###############"
      ],
      "metadata": {
        "id": "fjpsFTyoOffA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use this to test your code, if it prints True, you got the right answer\n",
        "\n",
        "abs(entropy_split(10,5,2,12) - 0.7606157383093077) <= 0.0001"
      ],
      "metadata": {
        "id": "dteBKOaTOjr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build a Categorical Decision Tree\n",
        "\n",
        "This dataset from UCI is about edible (`e`) and poisonous (`p`) mushrooms.\n",
        "\n",
        "- `gill-size`: `b` is for broad gills, `n` is for narrow gills.\n",
        "- `bruises`: `t` is for true, there are bruises, `f` for false, there are no bruises.\n",
        "- `poison`: `e` for edible, `p` for poison.\n",
        "\n",
        "We will cut the dataset down to just those three columns."
      ],
      "metadata": {
        "id": "vP4Qd1_YOkNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Mushroom Data\n",
        "\n",
        "# see this site for what variables mean: http://archive.ics.uci.edu/ml/datasets/Mushroom\n",
        "mush = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\")\n",
        "\n",
        "mush.columns = ['poison','cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size',\n",
        "                'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring',\n",
        "                'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number','ring-type',\n",
        "                'spore-print-color', 'population', 'habitat']\n",
        "\n",
        "mush.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "7KW1KdE0OplW",
        "outputId": "0781b76e-401e-4726-e319-d8c02f2f246b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  poison cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
              "0      e         x           s         y       t    a               f   \n",
              "1      e         b           s         w       t    l               f   \n",
              "2      p         x           y         w       t    p               f   \n",
              "3      e         x           s         g       f    n               f   \n",
              "4      e         x           y         y       t    a               f   \n",
              "\n",
              "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
              "0            c         b          k  ...                        s   \n",
              "1            c         b          n  ...                        s   \n",
              "2            c         n          n  ...                        s   \n",
              "3            w         b          k  ...                        s   \n",
              "4            c         b          n  ...                        s   \n",
              "\n",
              "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
              "0                      w                      w         p          w   \n",
              "1                      w                      w         p          w   \n",
              "2                      w                      w         p          w   \n",
              "3                      w                      w         p          w   \n",
              "4                      w                      w         p          w   \n",
              "\n",
              "  ring-number ring-type spore-print-color population habitat  \n",
              "0           o         p                 n          n       g  \n",
              "1           o         p                 n          n       m  \n",
              "2           o         p                 k          s       u  \n",
              "3           o         e                 n          a       g  \n",
              "4           o         p                 k          n       g  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94fae5df-b5d6-40be-b787-4d3ed53f9a13\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>poison</th>\n",
              "      <th>cap-shape</th>\n",
              "      <th>cap-surface</th>\n",
              "      <th>cap-color</th>\n",
              "      <th>bruises</th>\n",
              "      <th>odor</th>\n",
              "      <th>gill-attachment</th>\n",
              "      <th>gill-spacing</th>\n",
              "      <th>gill-size</th>\n",
              "      <th>gill-color</th>\n",
              "      <th>...</th>\n",
              "      <th>stalk-surface-below-ring</th>\n",
              "      <th>stalk-color-above-ring</th>\n",
              "      <th>stalk-color-below-ring</th>\n",
              "      <th>veil-type</th>\n",
              "      <th>veil-color</th>\n",
              "      <th>ring-number</th>\n",
              "      <th>ring-type</th>\n",
              "      <th>spore-print-color</th>\n",
              "      <th>population</th>\n",
              "      <th>habitat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>e</td>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>y</td>\n",
              "      <td>t</td>\n",
              "      <td>a</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>k</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e</td>\n",
              "      <td>b</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>t</td>\n",
              "      <td>l</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>n</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>p</td>\n",
              "      <td>x</td>\n",
              "      <td>y</td>\n",
              "      <td>w</td>\n",
              "      <td>t</td>\n",
              "      <td>p</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>k</td>\n",
              "      <td>s</td>\n",
              "      <td>u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>e</td>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>g</td>\n",
              "      <td>f</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>w</td>\n",
              "      <td>b</td>\n",
              "      <td>k</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>e</td>\n",
              "      <td>n</td>\n",
              "      <td>a</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>e</td>\n",
              "      <td>x</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>t</td>\n",
              "      <td>a</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>n</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>k</td>\n",
              "      <td>n</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94fae5df-b5d6-40be-b787-4d3ed53f9a13')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-94fae5df-b5d6-40be-b787-4d3ed53f9a13 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-94fae5df-b5d6-40be-b787-4d3ed53f9a13');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-74775ab6-f221-4310-a0fc-89d7932d74ee\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-74775ab6-f221-4310-a0fc-89d7932d74ee')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-74775ab6-f221-4310-a0fc-89d7932d74ee button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "mush"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mush_small = mush[[\"poison\", \"bruises\", \"gill-size\"]]"
      ],
      "metadata": {
        "id": "vDy0rwUEOsdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build!\n",
        "\n",
        "Use the functions you built earlier to build a (very small) decision tree that classifies each data point as either edible (`e`) or poisonous (`p`). You can choose to either use entropy or gini impurity.\n",
        "\n",
        "#### Layer 1\n",
        "\n",
        "Choose which variable to use to split the **first layer**. You have three options: leave the root node alone, split on gill-size, or split on bruises.\n"
      ],
      "metadata": {
        "id": "qcPxpx-kO1oO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# no split\n",
        "poison_split = {\"e\": np.sum(mush_small.poison == \"e\"),\n",
        "                \"p\": np.sum(mush_small.poison == \"p\")}\n",
        "\n",
        "poison_split"
      ],
      "metadata": {
        "id": "YR_FMD0rOtyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bruise split\n",
        "bruise_NodeF = mush_small.loc[mush_small.bruises == \"f\"] #node with bruise = F\n",
        "bruise_NodeT = mush_small.loc[mush_small.bruises == \"t\"] #node with bruise = T\n",
        "\n",
        "bruise_split = {\"f\": {\"e\": bruise_NodeF[bruise_NodeF.poison == \"e\"].shape[0],\n",
        "                              \"p\": bruise_NodeF.loc[bruise_NodeF.poison == \"p\"].shape[0]},\n",
        "                        \"t\": {\"e\": bruise_NodeT[bruise_NodeT.poison == \"e\"].shape[0],\n",
        "                              \"p\": bruise_NodeT.loc[bruise_NodeT.poison == \"p\"].shape[0]},}\n",
        "\n",
        "bruise_split"
      ],
      "metadata": {
        "id": "Kos1WO8bO7AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gill_NodeB = mush_small.loc[mush_small[\"gill-size\"] == \"b\"] #node with gill = b\n",
        "gill_NodeN = mush_small.loc[mush_small[\"gill-size\"] == \"n\"] #node with gill = n\n",
        "\n",
        "gill_split = {\"b\": {\"e\": gill_NodeB[gill_NodeB.poison == \"e\"].shape[0],\n",
        "                              \"p\": gill_NodeB.loc[gill_NodeB.poison == \"p\"].shape[0]},\n",
        "                        \"n\": {\"e\": gill_NodeN[gill_NodeN.poison == \"e\"].shape[0],\n",
        "                              \"p\": gill_NodeN.loc[gill_NodeN.poison == \"p\"].shape[0]},}\n",
        "\n",
        "gill_split"
      ],
      "metadata": {
        "id": "kQuDIh5gO9ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate impurity/entropy of each possible split using your functions\n",
        "\n",
        "# 1. no split (impurity/entropy of root node)\n",
        "\n",
        "\n",
        "# 2. split on bruise (impurity/entropy of bruise node)\n",
        "\n",
        "\n",
        "# 3. split on gill-size (impurity/entropy of gill node)"
      ],
      "metadata": {
        "id": "5ApAXU6aO_Na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# choose which split improves prediction most\n"
      ],
      "metadata": {
        "id": "hO29MI15PGSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO:\n",
        "\n",
        "Does splitting the root node improve the tree? How can you tell?\n",
        "\n",
        "\n",
        "### Create Classifications\n",
        "\n",
        "Pretend that this decision stump (a decision tree with only one layer, selected in the previous part) is your final tree. Generate the classification for each data point and store it in `mush_small`. You should end up with a column where the value is `e` if your predicted the mushroom is edible, and `p` if you predicted the model is poisonous.\n",
        "\n",
        "\n",
        "Remember, once you have chosen your split, we predict that the data point in each node is whatever class is most common in that node. For example, if you did no splits, and just used the root node, we would predict that all mushrooms are edible (`e`) because it is the most common in the root node (`{'e': 4208, 'p': 3915}`)."
      ],
      "metadata": {
        "id": "s5b5C2yfPIux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# classification\n"
      ],
      "metadata": {
        "id": "FydKoRjPPPKM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}